{"cells":[{"cell_type":"markdown","source":["# Lorenz-96 experiment\n","## From the paper \"Distribution-free inference with hierarchical data\"\n","### by Yonghoon Lee, Rina Foygel Barber, and Rebecca Willett\n","https://arxiv.org/abs/2306.06342\n","\n","The script reproduces the experiment in Section 4.\n"],"metadata":{"id":"9Xkqk13M4FFF"},"id":"9Xkqk13M4FFF"},{"cell_type":"code","source":["from google.colab import files\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd /content/drive/My Drive/DF/L96\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"id":"gXslu2zfaO8t","executionInfo":{"status":"error","timestamp":1697550549264,"user_tz":300,"elapsed":1052,"user":{"displayName":"Rebecca Willett","userId":"12820388659980941912"}},"outputId":"2d4a4df1-7907-4c80-c0da-e441ecb473a5"},"id":"gXslu2zfaO8t","execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-73f400fec89c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/My Drive/DF/L96'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     case = d.expect([\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(self, pattern, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mcompiled_pattern_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_pattern_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         return self.expect_list(compiled_pattern_list,\n\u001b[0m\u001b[1;32m    344\u001b[0m                 timeout, searchwindowsize, async_)\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpect_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     def expect_exact(self, pattern_list, timeout=-1, searchwindowsize=-1,\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincoming\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Keep reading until exception or return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","execution_count":null,"id":"2c161e87","metadata":{"id":"2c161e87"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","\n","import numpy as np\n","import pdb, random\n","import argparse, os\n","import matplotlib.pyplot as plt\n","import time\n","from tqdm import tqdm\n","from multiprocessing import Pool, cpu_count\n","import matplotlib.pyplot as plt\n","import warnings\n","import torch\n","from torch import nn\n","import torch.optim as optim\n","from l96_data import generate_l96_data, lorenz96, save_l96_data"]},{"cell_type":"markdown","id":"4a0aaf9f","metadata":{"id":"4a0aaf9f"},"source":["## Prepare the data"]},{"cell_type":"markdown","id":"ae796f16","metadata":{"id":"ae796f16"},"source":["##### Step 1: Randomly draw $k$ initial conditions from normal distributons and run the simulation model to time $T_0$.\n","\n","##### Step 2: For each group $k$, we perturb the state at $T_0$ by adding a slight amount of noise $\\eta_n$ for $n = 1,\\ldots,N_k$.\n","$$ u_{k, n}(T_0) = u_{k}(T_0) + r \\eta_{k,n},$$\n","where $ \\eta_n \\sim \\mathcal{N}(0, 1)$ and $r$ is a scalar.\n","\n","We then use $u_{k,n}$ as the initial conditions and run the L96 solver with the perturbed initial condtions for $K$ groups and $N_k$ perturbations for each group."]},{"cell_type":"code","execution_count":null,"id":"2af00096","metadata":{"id":"2af00096"},"outputs":[],"source":["r_eta_perturb = 0.5\n","time_step = 0.05\n","# spin up time T_0 for dynamical system\n","T_0 = 20\n","# run time T_max after perturbing state at time T_0\n","T_max = 5\n","# set time T at which we have response Y;\n","T = 0.5 # corresponds to Z_index = 10\n","#T = 0.05 # corresponds to Z_index = 1\n","T = round(T/time_step)*time_step # ensures Z_index an integer when T = Z_index * time_step\n","M = 10\n","K, N_k = 800, 50\n","\n","seeds_base = 0\n","train_data_folder = [f'train', seeds_base]\n","seeds_base = seeds_base + K * N_k\n","calibration_data_folder = [f'calibration', seeds_base]\n","seeds_base = seeds_base + K * N_k\n","test_data_folder = [f'test', seeds_base]"]},{"cell_type":"markdown","source":["####Generate and save new data"],"metadata":{"id":"cxZjYqb-zp4D"},"id":"cxZjYqb-zp4D"},{"cell_type":"code","source":["#train_tuple = save_l96_data(train_data_folder, time_step, T_0, T_max, K, N_k, r_eta_perturb, N = M)\n","#calibration_tuple = save_l96_data(calibration_data_folder, time_step, T_0, T_max, K, N_k, r_eta_perturb, N = M)\n","#test_tuple = save_l96_data(test_data_folder, time_step, T_0, T_max, K, N_k, r_eta_perturb, N = M)"],"metadata":{"id":"GcxnYFIpzVwT"},"id":"GcxnYFIpzVwT","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Load saved data"],"metadata":{"id":"rHrp3W010jet"},"id":"rHrp3W010jet"},{"cell_type":"code","execution_count":null,"id":"5277acc7","metadata":{"id":"5277acc7"},"outputs":[],"source":["train_tuple = torch.load(f'{train_data_folder[0]}.pth')\n","calibration_tuple = torch.load(f'{calibration_data_folder[0]}.pth')\n","test_tuple = torch.load(f'{test_data_folder[0]}.pth')"]},{"cell_type":"markdown","id":"d29eb980","metadata":{"id":"d29eb980"},"source":["### The saved data is a tuple that contains two parts:\n","##### E.g., for the training data:\n","The first part: the dynamic data generated from perturbed initial conditions.\n","- dim 0: number of samples $K= 800$\n","- dim 1: number of perturbations $N_k = 50$\n","- dim 2: number of time samples $T_{max}/dt=100$  where $dt$ = time_step\n","- dim 3: number of channels $M = 10$  \n","\n","The 2nd part: unperturbed initial conditions after T_0 burn out, this is our X used for training.  \n","- dim 0: number of samples $K = 800$  \n","- dim 1: number of pertrubtations $N_k = 50$   \n","- dim 2: number of channels $M = 10$"]},{"cell_type":"code","execution_count":null,"id":"235ffc03","metadata":{"id":"235ffc03"},"outputs":[],"source":["## X_train: unperturbed initial conditions of shape K x N_k x M.\n","X_train_np = train_tuple[1]\n","X_calibration_np = calibration_tuple[1]\n","X_test_np = test_tuple[1]\n","\n","## train_data: data generated from perturbed initial conditions of shape K x N_k x T_max x M.\n","train_data = train_tuple[0]\n","calibration_data = calibration_tuple[0]\n","test_data = test_tuple[0]\n","\n","train_data = train_data.reshape(-1, train_data.shape[-2], train_data.shape[-1])\n","calibration_data = calibration_data.reshape(-1, calibration_data.shape[-2], calibration_data.shape[-1])\n","test_data = test_data.reshape(-1, test_data.shape[-2], test_data.shape[-1])"]},{"cell_type":"markdown","id":"d6266919","metadata":{"id":"d6266919"},"source":["### After reshaping the data:\n","\n","- X_train is $40000 \\times 10 = KN_k \\times M$\n","- train_data is $40000 \\times 100 \\times 10 = KN_k \\times T_{max}/dt \\times M$ where $dt = $ time_step"]},{"cell_type":"markdown","id":"0cf2ef50","metadata":{"id":"0cf2ef50"},"source":["## If you want to rerun training, etc but not reload data, start here."]},{"cell_type":"code","execution_count":null,"id":"46fb8d7a","metadata":{"id":"46fb8d7a"},"outputs":[],"source":["random.seed(1)\n","np.random.seed(1)"]},{"cell_type":"code","execution_count":null,"id":"49e2a7de","metadata":{"id":"49e2a7de"},"outputs":[],"source":["## use state at u(T) as X and u(T + dt) as Y\n","\n","# T = Z_index * time_step\n","\n","Z_index = round(T/time_step)\n","Y_index = 0\n","\n","X_train = torch.from_numpy(X_train_np).float()\n","X_train_reshape = X_train.reshape(-1, X_train.shape[-1])\n","Z_train = torch.from_numpy(train_data[:, Z_index])\n","Z_train = Z_train.float()\n","Y_train = Z_train[:, Y_index].reshape(-1, 1)"]},{"cell_type":"code","execution_count":null,"id":"891716bd","metadata":{"id":"891716bd"},"outputs":[],"source":["Y_tr = train_tuple[0][:,:,Z_index,Y_index]\n","Y_train_sd = np.std(Y_tr,axis=1)\n","Y_train_sd = torch.from_numpy(Y_train_sd).float()\n","Y_train_sd_reshape = np.repeat(Y_train_sd,50).reshape(40000,1)"]},{"cell_type":"code","execution_count":null,"id":"8062019a","metadata":{"id":"8062019a"},"outputs":[],"source":["X_calibration = calibration_tuple[1][:,0,:]\n","X_calibration = torch.from_numpy(X_calibration).float()\n","Y_calibration = calibration_tuple[0][:,:,Z_index,Y_index]\n","X_test = test_tuple[1][:,0,:]\n","X_test = torch.from_numpy(X_test).float()\n","Y_test = test_tuple[0][:,:,Z_index,Y_index]"]},{"cell_type":"markdown","id":"c1942404","metadata":{"id":"c1942404"},"source":["### Initialize the NN"]},{"cell_type":"code","execution_count":null,"id":"9cbe60ee","metadata":{"id":"9cbe60ee"},"outputs":[],"source":["from torch import nn\n","\n","class Net(nn.Module):\n","    def __init__(self, input_dim=M, hidden_dim=20, output_dim=1):\n","        super(Net, self).__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.ReLU(),\n","#             nn.Linear(hidden_dim, hidden_dim),\n","#             nn.ReLU(),\n","            nn.Linear(hidden_dim, output_dim)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","# Instantiate the model\n","model = Net()"]},{"cell_type":"markdown","id":"eac64ef0","metadata":{"id":"eac64ef0"},"source":["### Start the training with SGD optimizer"]},{"cell_type":"markdown","source":["####Fit $\\hat{\\mu}$"],"metadata":{"id":"1S63AUT-kAYk"},"id":"1S63AUT-kAYk"},{"cell_type":"code","execution_count":null,"id":"cf518af0","metadata":{"scrolled":false,"id":"cf518af0"},"outputs":[],"source":["# Instantiate the model\n","model = Net()\n","\n","# Set the loss function and optimizer\n","loss_fn = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=9e-4)\n","\n","# Set the batch size\n","batch_size = 5000\n","n_epochs = 1000\n","n_samples = X_train_reshape.shape[0]\n","\n","# Start training\n","for epoch in tqdm(range(n_epochs)):\n","    permutation = torch.randperm(n_samples)\n","\n","    for i in range(0, n_samples, batch_size):\n","        optimizer.zero_grad()\n","\n","        # Create minibatch\n","        indices = permutation[i:i+batch_size]\n","        batch_x, batch_y = X_train_reshape[indices], Y_train[indices]\n","\n","        # Forward pass\n","        outputs = model(batch_x)\n","        loss = loss_fn(outputs, batch_y)\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","\n","        model.train()"]},{"cell_type":"markdown","source":["####Fit $\\hat{\\sigma}$"],"metadata":{"id":"9HIG0gmLkRt_"},"id":"9HIG0gmLkRt_"},{"cell_type":"code","execution_count":null,"id":"58d71ef2","metadata":{"id":"58d71ef2"},"outputs":[],"source":["# Instantiate the model\n","model_sd = Net()\n","\n","# Set the loss function and optimizer\n","loss_fn = nn.MSELoss()\n","optimizer = optim.Adam(model_sd.parameters(), lr=9e-4)\n","\n","# Set the batch size\n","batch_size = 5000\n","n_epochs = 1000\n","n_samples = X_train_reshape.shape[0]\n","\n","# Start training\n","for epoch in tqdm(range(n_epochs)):\n","    permutation = torch.randperm(n_samples)\n","\n","    for i in range(0, n_samples, batch_size):\n","        optimizer.zero_grad()\n","\n","        # Create minibatch\n","        indices = permutation[i:i+batch_size]\n","        batch_x, batch_y = X_train_reshape[indices], Y_train_sd_reshape[indices]\n","\n","        # Forward pass\n","        outputs = model_sd(batch_x)\n","        loss = loss_fn(outputs, batch_y)\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","\n","        model_sd.train()"]},{"cell_type":"markdown","source":["##Functions for running HCP and HCP$^2$"],"metadata":{"id":"ikvoeg2ReWUH"},"id":"ikvoeg2ReWUH"},{"cell_type":"code","execution_count":null,"id":"be4312fd","metadata":{"id":"be4312fd"},"outputs":[],"source":["#quantile function\n","def quantile(probs,values,level):\n","  values_rank = np.argsort(values)\n","  rank_alpha = np.min(np.where((np.cumsum(probs[values_rank]) >= 1-level) == True))\n","  q = values[values_rank[rank_alpha]]\n","  return q\n","\n","#HCP for data with repeated observations\n","def HCP_repeated_obs(X,Y_tilde,group_sizes,alpha,score):\n","  K = np.shape(X)[0]\n","\n","  values = []\n","  prob = []\n","\n","  for i in range(K):\n","    values = values+(score[i,:]).tolist()\n","    prob = prob+[1/((K+1)*group_sizes[i])]*group_sizes[i]\n","\n","  values = np.array(values+[np.inf])\n","  prob = np.array(prob+[1/(K+1)])\n","\n","  q_HCP = quantile(prob,values,alpha)\n","\n","  return q_HCP\n","\n","#HCP2 for data with repeated observations\n","def HCP2_repeated_obs(X,Y_tilde,group_sizes,alpha,score):\n","  K = np.shape(X)[0]\n","\n","  K_2 = np.sum(np.array(group_sizes[0:K]) >= 2)\n","  values = []\n","  prob = []\n","\n","  for i in range(K):\n","    if group_sizes[i] >= 2:\n","\n","      N_K = group_sizes[i]\n","      score_sorted = np.sort(score[i,:])\n","\n","      for j in range(N_K):\n","        values = values+[score_sorted[j]]\n","        prob = prob + [(N_K - (j+1))/((K_2+1)*N_K*(N_K-1)/2)]\n","\n","\n","  values = np.array(values+[np.inf])\n","  prob = np.array(prob+[1/(K_2+1)])\n","\n","  q_HCP2 = quantile(prob,values,alpha**2)\n","\n","  return q_HCP2"]},{"cell_type":"markdown","id":"f260f7d5","metadata":{"id":"f260f7d5"},"source":["## Run HCP \\& HCP$^2$"]},{"cell_type":"code","execution_count":null,"id":"82852b22","metadata":{"id":"82852b22"},"outputs":[],"source":["#get estimates and compute scores\n","model.eval()\n","muhat_calibration = model(X_calibration).reshape(800)\n","muhat_test = model(X_test).reshape(800)\n","muhat_calibration = muhat_calibration.detach().numpy()\n","muhat_test = muhat_test.detach().numpy()\n","\n","model_sd.eval()\n","sdhat_calibration = torch.abs(model_sd(X_calibration)).reshape(800)\n","sdhat_test = torch.abs(model_sd(X_test)).reshape(800)\n","sdhat_calibration = sdhat_calibration.detach().numpy()\n","sdhat_test = sdhat_test.detach().numpy()\n","\n","score_calibration = np.divide(np.abs(Y_calibration - np.outer(muhat_calibration,np.ones(N_k))),np.outer(sdhat_calibration,np.ones(N_k)))"]},{"cell_type":"code","execution_count":null,"id":"6ca9c461","metadata":{"id":"6ca9c461"},"outputs":[],"source":["#run HCP and HCP2\n","alpha=0.2\n","group_sizes = [N_k]*K\n","\n","q_HCP = HCP_repeated_obs(X_calibration,Y_calibration,group_sizes,alpha,score_calibration)\n","q_HCP2 = HCP2_repeated_obs(X_calibration,Y_calibration,group_sizes,alpha,score_calibration)\n","print(q_HCP,q_HCP2)"]},{"cell_type":"code","execution_count":null,"id":"fe2f5159","metadata":{"id":"fe2f5159"},"outputs":[],"source":["#compute conditional coverage rates and widths of prediction intervals\n","coverage_HCP = np.multiply(np.outer(muhat_test - q_HCP*sdhat_test,np.ones(50)) < Y_test , Y_test < np.outer(muhat_test + q_HCP*sdhat_test,np.ones(50)))\n","coverage_HCP2 = np.multiply(np.outer(muhat_test - q_HCP2*sdhat_test,np.ones(50)) < Y_test , Y_test < np.outer(muhat_test + q_HCP2*sdhat_test,np.ones(50)))\n","\n","conditional_coverage_HCP = np.mean(coverage_HCP,axis=1)\n","conditional_coverage_HCP2 = np.mean(coverage_HCP2,axis=1)\n","width_HCP = 2*q_HCP*sdhat_test\n","width_HCP2 = 2*q_HCP2*sdhat_test"]},{"cell_type":"code","execution_count":null,"id":"6135ecb0","metadata":{"id":"6135ecb0"},"outputs":[],"source":["result = np.vstack([conditional_coverage_HCP,conditional_coverage_HCP2,width_HCP,width_HCP2])\n","#save results\n","#np.save('T_5',result)"]},{"cell_type":"code","execution_count":null,"id":"41c581a7","metadata":{"id":"41c581a7"},"outputs":[],"source":["#load results\n","Z_1 = np.load('T_005.npy')\n","Z_10 = np.load('T_05.npy')"]},{"cell_type":"code","execution_count":null,"id":"ec00141e","metadata":{"id":"ec00141e"},"outputs":[],"source":["# Compute marginal/squared coverage rates\n","miscoverage_count_HCP_1 = N_k-Z_1[0,:]*N_k\n","squared_miscoverage_HCP_1 = np.mean(np.multiply(miscoverage_count_HCP_1,miscoverage_count_HCP_1)/(N_k*(N_k-1)))\n","squared_miscoverage_HCP_1_se = np.std(np.multiply(miscoverage_count_HCP_1,miscoverage_count_HCP_1)/(N_k*(N_k-1)))/np.sqrt(K)\n","miscoverage_count_HCP2_1 = N_k-Z_1[1,:]*N_k\n","squared_miscoverage_HCP2_1 = np.mean(np.multiply(miscoverage_count_HCP2_1,miscoverage_count_HCP2_1)/(N_k*(N_k-1)))\n","squared_miscoverage_HCP2_1_se = np.std(np.multiply(miscoverage_count_HCP2_1,miscoverage_count_HCP2_1)/(N_k*(N_k-1)))/np.sqrt(K)\n","miscoverage_count_HCP_10 = N_k-Z_10[0,:]*N_k\n","squared_miscoverage_HCP_10 = np.mean(np.multiply(miscoverage_count_HCP_10,miscoverage_count_HCP_10)/(N_k*(N_k-1)))\n","squared_miscoverage_HCP_10_se = np.std(np.multiply(miscoverage_count_HCP_10,miscoverage_count_HCP_10)/(N_k*(N_k-1)))/np.sqrt(K)\n","miscoverage_count_HCP2_10 = N_k-Z_10[1,:]*N_k\n","squared_miscoverage_HCP2_10 = np.mean(np.multiply(miscoverage_count_HCP2_10,miscoverage_count_HCP2_10)/(N_k*(N_k-1)))\n","squared_miscoverage_HCP2_10_se = np.std(np.multiply(miscoverage_count_HCP2_10,miscoverage_count_HCP2_10)/(N_k*(N_k-1)))/np.sqrt(K)"]},{"cell_type":"markdown","source":["###Table of coverage rates \\& widths"],"metadata":{"id":"snbw8SOufnJ7"},"id":"snbw8SOufnJ7"},{"cell_type":"code","execution_count":null,"id":"9cafb4c9","metadata":{"id":"9cafb4c9"},"outputs":[],"source":["#row : HCP(T=0.05) / HCP2(T=0.5) / HCP(T=0.5) / HCP2(T=0.5)\n","#column : marginal miscoverage rate / std / squared miscoverage rate / std / width / std\n","table = np.zeros((4,6))\n","table[0,:] = [1-np.mean(Z_1[0,:]),np.std(Z_1[0,:])/np.sqrt(K),squared_miscoverage_HCP_1,squared_miscoverage_HCP_1_se,np.mean(Z_1[2,:]),np.std(Z_1[2,:])/np.sqrt(K)]\n","table[1,:] = [1-np.mean(Z_1[1,:]),np.std(Z_1[1,:])/np.sqrt(K),squared_miscoverage_HCP2_1,squared_miscoverage_HCP2_1_se,np.mean(Z_1[3,:]),np.std(Z_1[3,:])/np.sqrt(K)]\n","table[2,:] = [1-np.mean(Z_10[0,:]),np.std(Z_10[0,:])/np.sqrt(K),squared_miscoverage_HCP_10,squared_miscoverage_HCP_10_se,np.mean(Z_10[2,:]),np.std(Z_10[2,:])/np.sqrt(K)]\n","table[3,:] = [1-np.mean(Z_10[1,:]),np.std(Z_10[1,:])/np.sqrt(K),squared_miscoverage_HCP2_10,squared_miscoverage_HCP2_10_se,np.mean(Z_10[3,:]),np.std(Z_10[3,:])/np.sqrt(K)]\n","np.set_printoptions(suppress=True)\n","print(np.round(table,4))"]},{"cell_type":"markdown","source":["###Histograms"],"metadata":{"id":"h48KvjcdfsmF"},"id":"h48KvjcdfsmF"},{"cell_type":"code","execution_count":null,"id":"b8acbe48","metadata":{"scrolled":false,"id":"b8acbe48"},"outputs":[],"source":["fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2,figsize=(16,10))\n","m=800\n","grid_coverage = np.linspace(0,1,41)\n","ax1.hist(1-Z_1[0,:],grid_coverage,histtype='stepfilled',color=(0.35,0.56,1,0.2),edgecolor = (0.35,0.56,1,1),weights=np.ones(m)/m, label = \"HCP\")\n","ax1.hist(1-Z_1[1,:],grid_coverage,histtype='stepfilled',color=(0.95,0.32,0.41,0.2),edgecolor = (0.95,0.32,0.41,1),weights=np.ones(m)/m, label = \"HCP$^2$\")\n","ax1.set_xlim([0,1])\n","ax1.set_ylim([0,0.2])\n","#ax1.set_xlabel(\"conditional miscoverage rates\",fontsize=20, labelpad=10)\n","ax1.vlines(0.2,ymin=0,ymax=0.3,linestyles=\"dashed\",color=\"black\")\n","ax1.tick_params(axis='x', labelsize=18)\n","ax1.tick_params(axis='y', labelsize=18)\n","ax1.set_ylabel(\"T = 0.05\", fontsize=20,labelpad=12)\n","ax1.legend(loc='upper right',fontsize=18)\n","\n","grid_width = np.linspace(1,2.2,41)\n","ax2.hist(Z_1[2,:],grid_width,histtype='stepfilled',color=(0.35,0.56,1,0.2),edgecolor = (0.35,0.56,1,1),weights=np.ones(m)/m, label = \"HCP\")\n","ax2.hist(Z_1[3,:],grid_width,histtype='stepfilled',color=(0.95,0.32,0.41,0.2),edgecolor = (0.95,0.32,0.41,1),weights=np.ones(m)/m, label = \"HCP$^2$\")\n","ax2.set_xlim([1,2.2])\n","ax2.set_ylim([0,0.2])\n","#ax2.set_xlabel(\"prediction interval widths\",fontsize=20, labelpad=10)\n","#ax2.vlines(0.2,ymin=0,ymax=0.35,linestyles=\"dashed\",color=\"black\")\n","ax2.tick_params(axis='x', labelsize=18)\n","ax2.tick_params(axis='y', labelsize=18)\n","ax2.legend(loc='upper right',fontsize=18)\n","\n","ax3.hist(1-Z_10[0,:],grid_coverage,histtype='stepfilled',color=(0.35,0.56,1,0.2),edgecolor = (0.35,0.56,1,1),weights=np.ones(m)/m, label = \"HCP\")\n","ax3.hist(1-Z_10[1,:],grid_coverage,histtype='stepfilled',color=(0.95,0.32,0.41,0.2),edgecolor = (0.95,0.32,0.41,1),weights=np.ones(m)/m, label = \"HCP$^2$\")\n","ax3.set_xlim([0,1])\n","ax3.set_ylim([0,1])\n","ax3.set_xlabel(\"conditional miscoverage rates\",fontsize=20, labelpad=10)\n","ax3.vlines(0.2,ymin=0,ymax=1,linestyles=\"dashed\",color=\"black\")\n","ax3.tick_params(axis='x', labelsize=18)\n","ax3.tick_params(axis='y', labelsize=18)\n","ax3.set_ylabel(\"T = 0.5\", fontsize=20,labelpad=12)\n","ax3.legend(loc='upper right',fontsize=18)\n","\n","grid_width = np.linspace(0,85,41)\n","ax4.hist(Z_10[2,:],grid_width,histtype='stepfilled',color=(0.35,0.56,1,0.2),edgecolor = (0.35,0.56,1,1),weights=np.ones(m)/m, label = \"HCP\")\n","ax4.hist(Z_10[3,:],grid_width,histtype='stepfilled',color=(0.95,0.32,0.41,0.2),edgecolor = (0.95,0.32,0.41,1),weights=np.ones(m)/m, label = \"HCP$^2$\")\n","ax4.set_xlim([0,85])\n","ax4.set_ylim([0,0.2])\n","ax4.set_xlabel(\"prediction interval widths\",fontsize=20, labelpad=10)\n","ax4.tick_params(axis='x', labelsize=18)\n","ax4.tick_params(axis='y', labelsize=18)\n","ax4.legend(loc='upper right',fontsize=18)\n","\n","fig.show()\n","#fig.savefig(('Z_index_1_10.png'),dpi=400,bbox_inches='tight')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}